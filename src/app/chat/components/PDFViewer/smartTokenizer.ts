/**
 * ìŠ¤ë§ˆíŠ¸ í† í°í™” ë° ì¡°í•© ì ìˆ˜ ì‹œìŠ¤í…œ
 * ì–¸ì–´ ê²½ê³„ë¥¼ ì¸ì‹í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ë¶„í• í•˜ê³ , ì¡°í•©ë³„ ì ìˆ˜ë¥¼ ë¶€ì—¬
 */

import { isCombinationOnlyWord } from './highlightConfig';

export interface SmartToken {
  text: string;
  type: 'korean' | 'english' | 'number' | 'symbol' | 'mixed';
  original: string;
}

export interface CombinationMatch {
  tokens: SmartToken[];
  matchedText: string;
  score: number; // ê¸°ë³¸ ì ìˆ˜ + ë³´ë„ˆìŠ¤ ì ìˆ˜
  baseScore: number; // ê¸°ë³¸ ë§¤ì¹­ ì ìˆ˜ (í† í° ê°œìˆ˜)
  bonusScore: number; // ì—°ì†ì„±/ì¸ì ‘ì„± ë³´ë„ˆìŠ¤ ì ìˆ˜
  startIndex: number;
  endIndex: number;
  continuity?: {
    hasDocumentContinuity: boolean; // ë¬¸ì„œ ë‚´ ì—°ì†ì„± ì¡´ì¬ ì—¬ë¶€
    proximityScore: number; // ì¸ì ‘ì„± ì ìˆ˜
    matchedSequences: string[]; // ë§¤ì¹­ëœ ì—°ì† ì‹œí€€ìŠ¤ë“¤
  };
}

/**
 * í•œêµ­ì–´ ë¶ˆìš©ì–´ ë° ì¡°ì‚¬ (í•„í„°ë§í•  ë‹¨ì–´ë“¤)
 */
const KOREAN_STOPWORDS = [
  // ì¡°ì‚¬
  'ì€', 'ëŠ”', 'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ë¡œ', 'ì™€', 'ê³¼', 'ì˜', 'ë„', 'ë§Œ', 'ì—ê²Œ', 'í•œí…Œ', 'ê»˜',
  'ì„œ', 'ë¶€í„°', 'ê¹Œì§€', 'ë³´ë‹¤', 'ì²˜ëŸ¼', 'ê°™ì´', 'ë§ˆë‹¤', 'ì¡°ì°¨', 'ë¼ë„', 'ì´ë‚˜', 'ë‚˜', 'ë“ ì§€', 'ê±°ë‚˜',
  // ì–´ë¯¸
  'ë‹¤', 'ì´ë‹¤', 'ì—ˆë‹¤', 'ì•˜ë‹¤', 'í–ˆë‹¤', 'ê² ë‹¤', 'ë„¤ìš”', 'ì–´ìš”', 'ì•„ìš”',
  // ì¼ë°˜ ë¶ˆìš©ì–´
  'ë°', 'ë“±', 'ê¸°íƒ€'
];

/**
 * íŠ¹ìˆ˜ë¬¸ì íŒ¨í„´ (ì œê±°í•  ë¬¸ìë“¤) - ìˆ«ì ì½¤ë§ˆëŠ” ë³´ì¡´
 */
const SPECIAL_CHARS = /[\|\-\(\)\[\]{};:!?'"~`@#$%^&*+=<>\/\\]/g;

/**
 * ì–¸ì–´ ê²½ê³„ ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸ í† í°í™”
 * ì˜ˆ: "ê°€ê³„CSSëŒ€ì¶œ" â†’ ["ê°€ê³„", "CSS", "ëŒ€ì¶œ"]
 *     "0.2ì–µ" â†’ ["0.2ì–µ"] (ìˆ«ì+ë‹¨ìœ„ëŠ” ìœ ì§€)
 *     "ë¹„ì ìš©" â†’ ["ë¹„ì ìš©"]
 */
export const smartTokenize = (text: string): SmartToken[] => {
  if (!text?.trim()) return [];
  
  // 1. íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì •ë¦¬
  const cleanText = text.replace(SPECIAL_CHARS, ' ').replace(/\s+/g, ' ').trim();
  
  // 2. ë„ì–´ì“°ê¸°ë¡œ 1ì°¨ ë¶„í• 
  const words = cleanText.split(' ').filter(word => word.trim());
  
  const tokens: SmartToken[] = [];
  
  words.forEach(word => {
    // ë¶ˆìš©ì–´ í•„í„°ë§
    if (KOREAN_STOPWORDS.includes(word.toLowerCase())) return;
    
    // 3. ê° ë‹¨ì–´ë¥¼ ì–¸ì–´ ê²½ê³„ë¡œ ì„¸ë¶„í™”
    const subTokens = splitByLanguageBoundary(word);
    tokens.push(...subTokens);
  });
  
  return tokens.filter(token => token.text.length > 0);
};

/**
 * ì–¸ì–´ ê²½ê³„ë¡œ ë‹¨ì–´ ë¶„í• 
 * ì˜ˆ: "ê°€ê³„CSSëŒ€ì¶œ" â†’ ["ê°€ê³„", "CSS", "ëŒ€ì¶œ"]
 *     "0.2ì–µ" â†’ ["0.2ì–µ"] (ìˆ«ì+í•œê¸€ ë‹¨ìœ„ëŠ” ìœ ì§€)
 */
const splitByLanguageBoundary = (word: string): SmartToken[] => {
  if (!word) return [];
  
  const tokens: SmartToken[] = [];
  let currentToken = '';
  let currentType: SmartToken['type'] | null = null;
  let tokenProcessed = false; // í† í°ì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
  
  for (let i = 0; i < word.length; i++) {
    const char = word[i];
    const charType = getCharacterType(char);
    
    // íŠ¹ìˆ˜ ì¼€ì´ìŠ¤: ìˆ«ì + í•œê¸€ ë‹¨ìœ„ (ì˜ˆ: "1,000ë§Œì›", "0.2ì–µ") - ë¶„ë¦¬í•˜ì§€ ì•ŠìŒ
    if (currentType === 'number' && charType === 'korean') {
      const remainingText = word.slice(i);
      if (/^[ì–µë§Œì²œì›ìœ„]+$/.test(remainingText)) {
        // ìˆ«ì+ë‹¨ìœ„ ì¡°í•©ì€ í•˜ë‚˜ë¡œ ìœ ì§€ (ì½¤ë§ˆ í¬í•¨ëœ ìˆ«ìë„ ì§€ì›)
        currentToken += remainingText;
        tokens.push({
          text: currentToken,
          type: 'mixed',
          original: currentToken
        });
        tokenProcessed = true; // í† í° ì²˜ë¦¬ ì™„ë£Œ í‘œì‹œ
        break;
      }
    }
    
    if (currentType === null || currentType === charType) {
      // ê°™ì€ íƒ€ì…ì´ë¯€ë¡œ ê³„ì† ì¶”ê°€
      currentToken += char;
      currentType = charType;
    } else {
      // íƒ€ì…ì´ ë°”ë€Œì—ˆìœ¼ë¯€ë¡œ ì´ì „ í† í° ì €ì¥
      if (currentToken.trim()) {
        tokens.push({
          text: currentToken.trim(),
          type: currentType,
          original: currentToken.trim()
        });
      }
      currentToken = char;
      currentType = charType;
    }
  }
  
  // ë§ˆì§€ë§‰ í† í° ì²˜ë¦¬ (ì´ë¯¸ ì²˜ë¦¬ëœ ê²½ìš° ì œì™¸)
  if (!tokenProcessed && currentToken.trim()) {
    tokens.push({
      text: currentToken.trim(),
      type: currentType || 'mixed',
      original: currentToken.trim()
    });
  }
  
  return tokens.filter(token => token.text.length > 0);
};

/**
 * ë¬¸ì íƒ€ì… íŒë³„ (ì½¤ë§ˆ í¬í•¨ ìˆ«ì ì§€ì›)
 */
const getCharacterType = (char: string): SmartToken['type'] => {
  if (/[ê°€-í£ã„±-ã…ã…-ã…£]/.test(char)) return 'korean';
  if (/[a-zA-Z]/.test(char)) return 'english';
  if (/[0-9.,]/.test(char)) return 'number'; // ì½¤ë§ˆì™€ ì ì„ ìˆ«ì íƒ€ì…ì— í¬í•¨
  return 'symbol';
};

/**
 * ë¬¸ì„œ ë‚´ ì—°ì†ì„± ë° ì¸ì ‘ì„± ì ìˆ˜ ê³„ì‚°
 */
const calculateDocumentContinuity = (
  documentText: string,
  searchTokens: SmartToken[],
  matchedText: string
): { hasDocumentContinuity: boolean; proximityScore: number; matchedSequences: string[] } => {
  const docWords = documentText.toLowerCase().split(/\s+/);
  const searchTokenTexts = searchTokens.map(t => t.text.toLowerCase());
  
  let proximityScore = 0;
  const matchedSequences: string[] = [];
  let hasDocumentContinuity = false;
  
  // ë¬¸ì„œì—ì„œ ì—°ì†ëœ í† í° ì‹œí€€ìŠ¤ ì°¾ê¸°
  for (let i = 0; i <= docWords.length - searchTokenTexts.length; i++) {
    const windowWords = docWords.slice(i, i + searchTokenTexts.length);
    
    // ì •í™•í•œ ìˆœì„œ ë§¤ì¹­ ì²´í¬
    let sequentialMatch = 0;
    let matchedInOrder: string[] = [];
    
    for (let j = 0; j < searchTokenTexts.length; j++) {
      const searchToken = searchTokenTexts[j];
      
      // í˜„ì¬ ìœ„ì¹˜ë¶€í„° maxDistance ë‚´ì—ì„œ ë§¤ì¹­ ì°¾ê¸°
      for (let k = j; k < Math.min(j + 3, windowWords.length); k++) {
        const docWord = windowWords[k];
        
        if (docWord.includes(searchToken) || searchToken.includes(docWord)) {
          sequentialMatch++;
          matchedInOrder.push(docWord);
          break;
        }
      }
    }
    
    // ë§¤ì¹­ ë¹„ìœ¨ ê³„ì‚°
    const matchRatio = sequentialMatch / searchTokenTexts.length;
    
    if (matchRatio >= 0.6) { // 60% ì´ìƒ ë§¤ì¹­
      hasDocumentContinuity = true;
      proximityScore += matchRatio;
      
      if (matchedInOrder.length >= 2) {
        matchedSequences.push(matchedInOrder.join(' '));
      }
    }
  }
  
  // ì¸ì ‘ì„± ë³´ë„ˆìŠ¤ (ê°™ì€ ë¬¸ì¥ ë‚´ì—ì„œ ê°€ê¹Œì´ ìˆëŠ” ê²½ìš°) - ìµœëŒ€ ì œí•œ
  const sentences = documentText.split(/[.!?]+/);
  let maxSentenceBonus = 0;
  
  for (const sentence of sentences) {
    const sentenceWords = sentence.toLowerCase().split(/\s+/);
    let foundTokens = 0;
    
    for (const searchToken of searchTokenTexts) {
      if (sentenceWords.some(word => 
        word.includes(searchToken) || searchToken.includes(word)
      )) {
        foundTokens++;
      }
    }
    
    if (foundTokens >= 2) {
      const sentenceBonus = foundTokens * 0.3; // ì¸ì ‘ì„± ë³´ë„ˆìŠ¤
      maxSentenceBonus = Math.max(maxSentenceBonus, sentenceBonus);
    }
  }
  
  proximityScore = Math.min(proximityScore + maxSentenceBonus, searchTokenTexts.length * 2); // ìµœëŒ€ê°’ ì œí•œ
  
  return {
    hasDocumentContinuity,
    proximityScore: Math.round(proximityScore * 10) / 10, // ì†Œìˆ˜ì  1ìë¦¬ë¡œ ë°˜ì˜¬ë¦¼
    matchedSequences
  };
};

/**
 * ë¬¸ì„œì—ì„œ ëª¨ë“  ê°€ëŠ¥í•œ ì¡°í•© ë§¤ì¹­ ì°¾ê¸° (ì—°ì†ì„± ì ìˆ˜ í¬í•¨)
 * 1ê°œ í† í° ë§¤ì¹­ = 1ì , 2ê°œ ì¡°í•© = 2ì , 3ê°œ ì¡°í•© = 3ì ... + ì—°ì†ì„± ë³´ë„ˆìŠ¤
 */
export const findCombinationMatches = (
  documentText: string,
  searchTokens: SmartToken[],
  config?: { 
    singleTokenScore?: number;
    combinationBonus?: number;
    continuityBonus?: number;
    proximityBonus?: number;
    minScore?: number;
    maxScore?: number;
  }
): CombinationMatch[] => {
  // ê¸°ë³¸ê°’ ì„¤ì •
  const {
    singleTokenScore = 1,
    combinationBonus = 1,
    continuityBonus = 1,
    proximityBonus = 0.5,
    minScore = 1,
    maxScore = 10
  } = config || {};
  if (!documentText || searchTokens.length === 0) return [];
  
  const matches: CombinationMatch[] = [];
  const docLower = documentText.toLowerCase();
  
  // ê°œë³„ í† í° ë§¤ì¹­ (ì—°ì†ì„± ì ìˆ˜ í¬í•¨ + ì¡°í•© ì „ìš© ë‹¨ì–´ í•„í„°ë§)
  searchTokens.forEach(token => {
    const tokenLower = token.text.toLowerCase();
    let startIndex = 0;
    
    while (true) {
      const index = docLower.indexOf(tokenLower, startIndex);
      if (index === -1) break;
      
      // ë‹¨ì–´ ê²½ê³„ í™•ì¸ (í•œêµ­ì–´ëŠ” ë” ìœ ì—°í•˜ê²Œ)
      if (isValidWordBoundary(docLower, index, tokenLower)) {
        const matchedText = documentText.substring(index, index + tokenLower.length);
        
        // ì—°ì†ì„± ì ìˆ˜ ê³„ì‚°
        const continuity = calculateDocumentContinuity(documentText, [token], matchedText);
        
        const baseScore = singleTokenScore;
        const bonusScore = (continuity.hasDocumentContinuity ? continuityBonus : 0) + 
                          (continuity.proximityScore * proximityBonus);
        let finalScore = Math.min(baseScore + bonusScore, maxScore);
        
        // ğŸ¯ ì¡°í•© ì „ìš© ë‹¨ì–´ í•„í„°ë§: ë‹¨ë…ìœ¼ë¡œëŠ” ë†’ì€ ì ìˆ˜ë¥¼ ë°›ì„ ìˆ˜ ì—†ìŒ
        if (isCombinationOnlyWord(token.text)) {
          // ì¡°í•© ì „ìš© ë‹¨ì–´ëŠ” ë‹¨ë…ìœ¼ë¡œëŠ” ë§¤ìš° ë‚®ì€ ì ìˆ˜ë§Œ ë¶€ì—¬
          finalScore = Math.min(finalScore, 0.5);
        }
        
        // ìµœì†Œ ì ìˆ˜ ì´ìƒì¸ ê²½ìš°ë§Œ ì¶”ê°€
        if (finalScore >= minScore) {
          matches.push({
            tokens: [token],
            matchedText,
            score: Math.round(finalScore * 10) / 10,
            baseScore,
            bonusScore: Math.round(bonusScore * 10) / 10,
            startIndex: index,
            endIndex: index + tokenLower.length,
            continuity
          });
        }
      }
      
      startIndex = index + 1;
    }
  });
  
  // 2ì  ì´ìƒ: í† í° ì¡°í•© ë§¤ì¹­
  for (let combSize = 2; combSize <= Math.min(4, searchTokens.length); combSize++) {
    findCombinationMatchesOfSize(documentText, searchTokens, combSize, matches, {
      singleTokenScore,
      combinationBonus,
      continuityBonus,
      proximityBonus,
      minScore,
      maxScore
    });
  }
  
  // ê²¹ì¹˜ëŠ” ë§¤ì¹­ ì œê±° (ì ìˆ˜ê°€ ë†’ì€ ê²ƒ ìš°ì„ )
  return removeDuplicateMatches(matches);
};

/**
 * íŠ¹ì • í¬ê¸°ì˜ ì¡°í•© ë§¤ì¹­ ì°¾ê¸° (ì—°ì†ì„± ì ìˆ˜ í¬í•¨)
 */
const findCombinationMatchesOfSize = (
  documentText: string,
  searchTokens: SmartToken[],
  combSize: number,
  matches: CombinationMatch[],
  config: {
    singleTokenScore: number;
    combinationBonus: number;
    continuityBonus: number;
    proximityBonus: number;
    minScore: number;
    maxScore: number;
  }
) => {
  const { singleTokenScore, combinationBonus, continuityBonus, proximityBonus, minScore, maxScore } = config;
  const docLower = documentText.toLowerCase();
  
  // ëª¨ë“  ê°€ëŠ¥í•œ í† í° ì¡°í•© ìƒì„±
  for (let i = 0; i <= searchTokens.length - combSize; i++) {
    const tokenCombination = searchTokens.slice(i, i + combSize);
    
    // ì¡°í•©ëœ í…ìŠ¤íŠ¸ë“¤ì„ ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ê²€ìƒ‰
    // 1) ì—°ì†ëœ ì¡°í•©: "ê°€ê³„ CSS ëŒ€ì¶œ"
    const spaceJoined = tokenCombination.map(t => t.text).join(' ').toLowerCase();
    // 2) ë¶™ì¸ ì¡°í•©: "ê°€ê³„CSSëŒ€ì¶œ" 
    const directJoined = tokenCombination.map(t => t.text).join('').toLowerCase();
    
    [spaceJoined, directJoined].forEach(searchPattern => {
      if (searchPattern.length < 2) return;
      
      let startIndex = 0;
      while (true) {
        const index = docLower.indexOf(searchPattern, startIndex);
        if (index === -1) break;
        
        if (isValidWordBoundary(docLower, index, searchPattern)) {
          const matchedText = documentText.substring(index, index + searchPattern.length);
          
          // ì—°ì†ì„± ì ìˆ˜ ê³„ì‚°
          const continuity = calculateDocumentContinuity(documentText, tokenCombination, matchedText);
          
          const baseScore = combSize * singleTokenScore + (combSize - 1) * combinationBonus;
          const bonusScore = (continuity.hasDocumentContinuity ? continuityBonus : 0) + 
                            (continuity.proximityScore * proximityBonus);
          let finalScore = Math.min(baseScore + bonusScore, maxScore);
          
          // ğŸ¯ ì¡°í•©ì—ì„œëŠ” ì¡°í•© ì „ìš© ë‹¨ì–´ë“¤ì´ ì •ìƒì ì¸ ì ìˆ˜ë¥¼ ë°›ìŒ
          // ì¡°í•© ì „ìš© ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì¡°í•© ë³´ë„ˆìŠ¤ ì¶”ê°€ ì ìš©
          const hasCombinationOnlyWords = tokenCombination.some(token => 
            isCombinationOnlyWord(token.text)
          );
          
          if (hasCombinationOnlyWords && combSize >= 2) {
            // ì¡°í•© ì „ìš© ë‹¨ì–´ê°€ í¬í•¨ëœ ì¡°í•©ì—ëŠ” ì¶”ê°€ ë³´ë„ˆìŠ¤
            finalScore = Math.min(finalScore + combinationBonus * 0.5, maxScore);
          }
          
          // ìµœì†Œ ì ìˆ˜ ì´ìƒì¸ ê²½ìš°ë§Œ ì¶”ê°€
          if (finalScore >= minScore) {
            matches.push({
              tokens: tokenCombination,
              matchedText,
              score: Math.round(finalScore * 10) / 10,
              baseScore,
              bonusScore: Math.round(bonusScore * 10) / 10,
              startIndex: index,
              endIndex: index + searchPattern.length,
              continuity
            });
          }
        }
        
        startIndex = index + 1;
      }
    });
  }
};

/**
 * ë‹¨ì–´ ê²½ê³„ ìœ íš¨ì„± ê²€ì‚¬ (í•œêµ­ì–´ ì¹œí™”ì )
 */
const isValidWordBoundary = (text: string, index: number, pattern: string): boolean => {
  const beforeChar = index > 0 ? text[index - 1] : ' ';
  const afterChar = index + pattern.length < text.length ? text[index + pattern.length] : ' ';
  
  // í•œêµ­ì–´ëŠ” ê²½ê³„ ê²€ì‚¬ë¥¼ ë” ìœ ì—°í•˜ê²Œ
  const isWordBoundary = (
    /[\s.,\-|()[\]{}~]/.test(beforeChar) ||
    /[\s.,\-|()[\]{}~]/.test(afterChar) ||
    index === 0 ||
    index + pattern.length === text.length ||
    !/[ê°€-í£a-zA-Z0-9]/.test(beforeChar) ||
    !/[ê°€-í£a-zA-Z0-9]/.test(afterChar)
  );
  
  return isWordBoundary;
};

/**
 * ê²¹ì¹˜ëŠ” ë§¤ì¹­ ì œê±° (ì ìˆ˜ê°€ ë†’ì€ ê²ƒ ìš°ì„  ìœ ì§€)
 */
const removeDuplicateMatches = (matches: CombinationMatch[]): CombinationMatch[] => {
  // ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
  const sortedMatches = matches.sort((a, b) => b.score - a.score);
  const finalMatches: CombinationMatch[] = [];
  
  for (const match of sortedMatches) {
    // ê¸°ì¡´ ë§¤ì¹­ë“¤ê³¼ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸
    const hasOverlap = finalMatches.some(existing => 
      (match.startIndex < existing.endIndex && match.endIndex > existing.startIndex)
    );
    
    if (!hasOverlap) {
      finalMatches.push(match);
    }
  }
  
  return finalMatches;
};

/**
 * í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
 */
export const testSmartTokenizer = () => {
  const testText = "ê°€ê³„CSSëŒ€ì¶œ | ë¹„ì ìš© ëŒ€ìƒ ë° ì¬ì‹¬ì‚¬(ì‹ ìš©ëŒ€ì¶œ) | - | - | 1,000ë§Œì› ì´í•˜ | 3,000ë§Œì› ì´í•˜ | 0.2ì–µ ì´ˆê³¼ | - | -";
  
  console.log('=== ìŠ¤ë§ˆíŠ¸ í† í°í™” í…ŒìŠ¤íŠ¸ ===');
  console.log('ì…ë ¥:', testText);
  
  const tokens = smartTokenize(testText);
  console.log('í† í°í™” ê²°ê³¼:');
  tokens.forEach((token, i) => {
    const isCombOnly = isCombinationOnlyWord(token.text) ? ' [ì¡°í•©ì „ìš©]' : '';
    console.log(`  ${i + 1}. "${token.text}" (${token.type})${isCombOnly}`);
  });
  
  const docText = "ê°€ê³„ ëŒ€ì¶œ CSSëŒ€ì¶œ ì ìš© ìë™ìŠ¹ì¸ ê°€ê³„ CSS ëŒ€ì¶œ ë¹„ì ìš© ëŒ€ìƒ ë° ì¬ì‹¬ì‚¬ ì‹ ìš©ëŒ€ì¶œ 1,000ë§Œì› ì´í•˜ 3,000ë§Œì› ì´í•˜ 0.2ì–µ ì´ˆê³¼ ê¸°íƒ€ì§€ì—­";
  const matches = findCombinationMatches(docText, tokens, {
    singleTokenScore: 1,
    combinationBonus: 1,
    continuityBonus: 1,
    proximityBonus: 0.5,
    minScore: 1,
    maxScore: 10
  });
  
  console.log('\në§¤ì¹­ ê²°ê³¼ (ì¡°í•© ì „ìš© ë‹¨ì–´ í•„í„°ë§ ì ìš©):');
  matches.forEach((match, i) => {
    const combOnlyTokens = match.tokens.filter(t => isCombinationOnlyWord(t.text));
    const hasCombOnly = combOnlyTokens.length > 0 ? ` [ì¡°í•©ì „ìš©: ${combOnlyTokens.map(t => t.text).join(', ')}]` : '';
    console.log(`  ${i + 1}. "${match.matchedText}" (${match.score}ì ) - í† í°: [${match.tokens.map(t => t.text).join(', ')}]${hasCombOnly}`);
  });
  
  return { tokens, matches };
};